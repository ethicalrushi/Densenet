{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Internshala Assignment DNST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "outputId": "270c4c3a-2a5f-4b45-a5ac-d66a641a6c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras\n",
        "!pip install h5py pyyaml "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YcDaB0JYj06Z",
        "colab_type": "code",
        "outputId": "ac2d27ff-a676-45a2-8f93-92bf2276904a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "wk7yaGuKj5KP",
        "colab_type": "code",
        "outputId": "4fdc84b5-db0f-4490-8266-c5fcda7a857a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.5 GB  | Proc size: 749.9 MB\n",
            "GPU RAM Free: 11320MB | Used: 121MB | Util   1% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y0uYkCzSkbiL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation, GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 250\n",
        "l = 38\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "outputId": "13c8eb12-9331-453e-e0c0-a026c2fcbc68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 20s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Vwlp04WFIu5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(x):\n",
        "    min_val = np.min(x)\n",
        "    max_val = np.max(x)\n",
        "    \n",
        "    x = (x-min_val)/(max_val-min_val)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tyoirpb5FXgi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = normalize(x_train)\n",
        "x_test = normalize(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    cv = Conv2D(10, (1,1), use_bias=False ,padding='same')(relu)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(cv)\n",
        "    pooling = GlobalAveragePooling2D()(avg)\n",
        "    output = Activation('softmax')(pooling)\n",
        "    #output = Dense(num_classes, activation='softmax')(pooling)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "outputId": "803962df-920d-4c2a-d9d7-03eee35531d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "num_filter = 12\n",
        "dropout_rate = 0.2\n",
        "l=36\n",
        "\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(16, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "outputId": "4add8e0a-0ec7-4224-c724-04b217dda4f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 22848
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   432         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 6)    864         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 22)   0           conv2d_1[0][0]                   \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 22)   88          concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 22)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 6)    1188        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 28)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 28)   112         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 28)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 6)    1512        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 34)   0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 34)   136         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 34)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 6)    1836        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 40)   0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 40)   160         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 40)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 6)    2160        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 46)   0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 46)   184         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 46)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 6)    2484        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 52)   0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 52)   208         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 52)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 6)    2808        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 58)   0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 58)   232         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 58)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 6)    3132        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 64)   0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 64)   256         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 6)    3456        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 70)   0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 70)   280         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 70)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 6)    3780        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 76)   0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 76)   304         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 76)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 6)    4104        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 82)   0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 82)   328         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 82)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 6)    4428        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 88)   0           concatenate_11[0][0]             \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 88)   352         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 88)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 6)    4752        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 94)   0           concatenate_12[0][0]             \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 94)   376         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 94)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 6)    5076        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 100)  0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 100)  400         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 100)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 6)    5400        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 106)  0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 106)  424         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 106)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 6)    5724        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 32, 32, 112)  0           concatenate_15[0][0]             \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 112)  448         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 112)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 6)    6048        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 32, 32, 118)  0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 118)  472         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 118)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 6)    6372        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 32, 32, 124)  0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 124)  496         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 124)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 6)    6696        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 32, 32, 130)  0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 130)  520         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 130)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 6)    7020        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 32, 32, 136)  0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 136)  544         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 136)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 6)    7344        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 32, 32, 142)  0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 142)  568         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 142)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 6)    7668        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 32, 32, 148)  0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 148)  592         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 148)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 6)    7992        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 32, 32, 154)  0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 154)  616         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 154)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 6)    8316        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 32, 32, 160)  0           concatenate_23[0][0]             \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 160)  640         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 160)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 6)    8640        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 32, 32, 166)  0           concatenate_24[0][0]             \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 166)  664         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 166)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 6)    8964        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 32, 32, 172)  0           concatenate_25[0][0]             \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 32, 32, 172)  688         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 32, 32, 172)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 6)    9288        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 32, 32, 178)  0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 32, 32, 178)  712         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 32, 32, 178)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 6)    9612        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 32, 32, 184)  0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 32, 32, 184)  736         concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 184)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 6)    9936        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 32, 32, 190)  0           concatenate_28[0][0]             \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 32, 32, 190)  760         concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 190)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 6)    10260       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 32, 32, 196)  0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 196)  784         concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 196)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 32, 6)    10584       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 32, 32, 202)  0           concatenate_30[0][0]             \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 32, 32, 202)  808         concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 202)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 32, 32, 6)    10908       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 32, 32, 208)  0           concatenate_31[0][0]             \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 32, 32, 208)  832         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 32, 32, 208)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 32, 32, 6)    11232       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 32, 32, 214)  0           concatenate_32[0][0]             \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 32, 32, 214)  856         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 32, 32, 214)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 32, 32, 6)    11556       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 32, 32, 220)  0           concatenate_33[0][0]             \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 32, 32, 220)  880         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 32, 32, 220)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 32, 32, 6)    11880       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 32, 32, 226)  0           concatenate_34[0][0]             \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 32, 32, 226)  904         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 32, 32, 226)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 32, 32, 6)    12204       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 32, 32, 232)  0           concatenate_35[0][0]             \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 32, 32, 232)  928         concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 32, 32, 232)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 32, 32, 6)    1392        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 6)    0           conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 16, 16, 6)    24          average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 16, 16, 6)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 6)    324         activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 16, 16, 12)   0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 16, 16, 12)   48          concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 16, 16, 12)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 6)    648         activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 16, 16, 18)   0           concatenate_37[0][0]             \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 16, 16, 18)   72          concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 16, 16, 18)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 16, 16, 6)    972         activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 16, 16, 24)   0           concatenate_38[0][0]             \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 16, 16, 24)   96          concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 16, 16, 24)   0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 16, 16, 6)    1296        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 16, 16, 30)   0           concatenate_39[0][0]             \n",
            "                                                                 conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 16, 16, 30)   120         concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 16, 16, 30)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 16, 16, 6)    1620        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 16, 16, 36)   0           concatenate_40[0][0]             \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 16, 16, 36)   144         concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 16, 16, 36)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 16, 16, 6)    1944        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 16, 16, 42)   0           concatenate_41[0][0]             \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 16, 16, 42)   168         concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 16, 16, 42)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 6)    2268        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 16, 16, 48)   0           concatenate_42[0][0]             \n",
            "                                                                 conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 48)   192         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 16, 16, 48)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 6)    2592        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 16, 16, 54)   0           concatenate_43[0][0]             \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 54)   216         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 54)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 16, 16, 6)    2916        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 16, 16, 60)   0           concatenate_44[0][0]             \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 60)   240         concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 60)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 6)    3240        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 16, 16, 66)   0           concatenate_45[0][0]             \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 66)   264         concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 66)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 6)    3564        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 16, 16, 72)   0           concatenate_46[0][0]             \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 72)   288         concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 72)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 6)    3888        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 16, 16, 78)   0           concatenate_47[0][0]             \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 78)   312         concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 78)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 6)    4212        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 16, 16, 84)   0           concatenate_48[0][0]             \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 84)   336         concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 84)   0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 6)    4536        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 16, 16, 90)   0           concatenate_49[0][0]             \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 16, 16, 90)   360         concatenate_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 90)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 6)    4860        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 16, 16, 96)   0           concatenate_50[0][0]             \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 16, 16, 96)   384         concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 96)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 6)    5184        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 16, 16, 102)  0           concatenate_51[0][0]             \n",
            "                                                                 conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 102)  408         concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 102)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 6)    5508        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 16, 16, 108)  0           concatenate_52[0][0]             \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 108)  432         concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 108)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 6)    5832        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 16, 16, 114)  0           concatenate_53[0][0]             \n",
            "                                                                 conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 114)  456         concatenate_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 114)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 6)    6156        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 16, 16, 120)  0           concatenate_54[0][0]             \n",
            "                                                                 conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 120)  480         concatenate_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 120)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 6)    6480        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 16, 16, 126)  0           concatenate_55[0][0]             \n",
            "                                                                 conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 126)  504         concatenate_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 126)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 6)    6804        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_57 (Concatenate)    (None, 16, 16, 132)  0           concatenate_56[0][0]             \n",
            "                                                                 conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 132)  528         concatenate_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 132)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 6)    7128        activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_58 (Concatenate)    (None, 16, 16, 138)  0           concatenate_57[0][0]             \n",
            "                                                                 conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 138)  552         concatenate_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 138)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 6)    7452        activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_59 (Concatenate)    (None, 16, 16, 144)  0           concatenate_58[0][0]             \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 144)  576         concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 144)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 6)    7776        activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_60 (Concatenate)    (None, 16, 16, 150)  0           concatenate_59[0][0]             \n",
            "                                                                 conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 150)  600         concatenate_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 150)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 6)    8100        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_61 (Concatenate)    (None, 16, 16, 156)  0           concatenate_60[0][0]             \n",
            "                                                                 conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 156)  624         concatenate_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 156)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 6)    8424        activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_62 (Concatenate)    (None, 16, 16, 162)  0           concatenate_61[0][0]             \n",
            "                                                                 conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 162)  648         concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 162)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 6)    8748        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_63 (Concatenate)    (None, 16, 16, 168)  0           concatenate_62[0][0]             \n",
            "                                                                 conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 168)  672         concatenate_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 168)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 6)    9072        activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_64 (Concatenate)    (None, 16, 16, 174)  0           concatenate_63[0][0]             \n",
            "                                                                 conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 16, 16, 174)  696         concatenate_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 16, 16, 174)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 16, 16, 6)    9396        activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_65 (Concatenate)    (None, 16, 16, 180)  0           concatenate_64[0][0]             \n",
            "                                                                 conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 16, 16, 180)  720         concatenate_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 16, 16, 180)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 16, 16, 6)    9720        activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_66 (Concatenate)    (None, 16, 16, 186)  0           concatenate_65[0][0]             \n",
            "                                                                 conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 16, 16, 186)  744         concatenate_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 16, 16, 186)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 16, 16, 6)    10044       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_67 (Concatenate)    (None, 16, 16, 192)  0           concatenate_66[0][0]             \n",
            "                                                                 conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 16, 16, 192)  768         concatenate_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 16, 16, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 16, 16, 6)    10368       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_68 (Concatenate)    (None, 16, 16, 198)  0           concatenate_67[0][0]             \n",
            "                                                                 conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 16, 16, 198)  792         concatenate_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 16, 16, 198)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 16, 16, 6)    10692       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_69 (Concatenate)    (None, 16, 16, 204)  0           concatenate_68[0][0]             \n",
            "                                                                 conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 16, 16, 204)  816         concatenate_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 16, 16, 204)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 16, 16, 6)    11016       activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_70 (Concatenate)    (None, 16, 16, 210)  0           concatenate_69[0][0]             \n",
            "                                                                 conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 16, 16, 210)  840         concatenate_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 16, 16, 210)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 16, 16, 6)    11340       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_71 (Concatenate)    (None, 16, 16, 216)  0           concatenate_70[0][0]             \n",
            "                                                                 conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 16, 16, 216)  864         concatenate_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 16, 16, 216)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 16, 16, 6)    11664       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_72 (Concatenate)    (None, 16, 16, 222)  0           concatenate_71[0][0]             \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 16, 16, 222)  888         concatenate_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 16, 16, 222)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 16, 16, 6)    1332        activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 8, 8, 6)      0           conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 6)      24          average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 6)      0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 6)      324         activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_73 (Concatenate)    (None, 8, 8, 12)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 12)     48          concatenate_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 12)     0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 6)      648         activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_74 (Concatenate)    (None, 8, 8, 18)     0           concatenate_73[0][0]             \n",
            "                                                                 conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 18)     72          concatenate_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 18)     0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 6)      972         activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_75 (Concatenate)    (None, 8, 8, 24)     0           concatenate_74[0][0]             \n",
            "                                                                 conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 24)     96          concatenate_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 24)     0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 6)      1296        activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_76 (Concatenate)    (None, 8, 8, 30)     0           concatenate_75[0][0]             \n",
            "                                                                 conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 30)     120         concatenate_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 30)     0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 6)      1620        activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_77 (Concatenate)    (None, 8, 8, 36)     0           concatenate_76[0][0]             \n",
            "                                                                 conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 36)     144         concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 36)     0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 6)      1944        activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_78 (Concatenate)    (None, 8, 8, 42)     0           concatenate_77[0][0]             \n",
            "                                                                 conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 42)     168         concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 42)     0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 6)      2268        activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_79 (Concatenate)    (None, 8, 8, 48)     0           concatenate_78[0][0]             \n",
            "                                                                 conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 48)     192         concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 48)     0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 6)      2592        activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_80 (Concatenate)    (None, 8, 8, 54)     0           concatenate_79[0][0]             \n",
            "                                                                 conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 54)     216         concatenate_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 54)     0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 6)      2916        activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_81 (Concatenate)    (None, 8, 8, 60)     0           concatenate_80[0][0]             \n",
            "                                                                 conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 60)     240         concatenate_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 60)     0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 6)      3240        activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_82 (Concatenate)    (None, 8, 8, 66)     0           concatenate_81[0][0]             \n",
            "                                                                 conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 66)     264         concatenate_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 66)     0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 6)      3564        activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_83 (Concatenate)    (None, 8, 8, 72)     0           concatenate_82[0][0]             \n",
            "                                                                 conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 72)     288         concatenate_83[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 72)     0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 6)      3888        activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_84 (Concatenate)    (None, 8, 8, 78)     0           concatenate_83[0][0]             \n",
            "                                                                 conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 78)     312         concatenate_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 78)     0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 6)      4212        activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_85 (Concatenate)    (None, 8, 8, 84)     0           concatenate_84[0][0]             \n",
            "                                                                 conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 84)     336         concatenate_85[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 84)     0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 6)      4536        activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_86 (Concatenate)    (None, 8, 8, 90)     0           concatenate_85[0][0]             \n",
            "                                                                 conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 90)     360         concatenate_86[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 90)     0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 6)      4860        activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_87 (Concatenate)    (None, 8, 8, 96)     0           concatenate_86[0][0]             \n",
            "                                                                 conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 96)     384         concatenate_87[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 96)     0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 6)      5184        activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_88 (Concatenate)    (None, 8, 8, 102)    0           concatenate_87[0][0]             \n",
            "                                                                 conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 102)    408         concatenate_88[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 102)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 6)      5508        activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_89 (Concatenate)    (None, 8, 8, 108)    0           concatenate_88[0][0]             \n",
            "                                                                 conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 108)    432         concatenate_89[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 108)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 6)      5832        activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_90 (Concatenate)    (None, 8, 8, 114)    0           concatenate_89[0][0]             \n",
            "                                                                 conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 114)    456         concatenate_90[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 114)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 6)      6156        activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_91 (Concatenate)    (None, 8, 8, 120)    0           concatenate_90[0][0]             \n",
            "                                                                 conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 120)    480         concatenate_91[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 8, 8, 120)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 8, 8, 6)      6480        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_92 (Concatenate)    (None, 8, 8, 126)    0           concatenate_91[0][0]             \n",
            "                                                                 conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 8, 8, 126)    504         concatenate_92[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 8, 8, 126)    0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 8, 8, 6)      6804        activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_93 (Concatenate)    (None, 8, 8, 132)    0           concatenate_92[0][0]             \n",
            "                                                                 conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 8, 8, 132)    528         concatenate_93[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 8, 8, 132)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 8, 8, 6)      7128        activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_94 (Concatenate)    (None, 8, 8, 138)    0           concatenate_93[0][0]             \n",
            "                                                                 conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 8, 8, 138)    552         concatenate_94[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 8, 8, 138)    0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 8, 8, 6)      7452        activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_95 (Concatenate)    (None, 8, 8, 144)    0           concatenate_94[0][0]             \n",
            "                                                                 conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 8, 8, 144)    576         concatenate_95[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 8, 8, 144)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 8, 8, 6)      7776        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_96 (Concatenate)    (None, 8, 8, 150)    0           concatenate_95[0][0]             \n",
            "                                                                 conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 8, 8, 150)    600         concatenate_96[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 8, 8, 150)    0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 8, 8, 6)      8100        activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_97 (Concatenate)    (None, 8, 8, 156)    0           concatenate_96[0][0]             \n",
            "                                                                 conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 8, 8, 156)    624         concatenate_97[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 8, 8, 156)    0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 8, 8, 6)      8424        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_98 (Concatenate)    (None, 8, 8, 162)    0           concatenate_97[0][0]             \n",
            "                                                                 conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 8, 8, 162)    648         concatenate_98[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 8, 8, 162)    0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 8, 8, 6)      8748        activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_99 (Concatenate)    (None, 8, 8, 168)    0           concatenate_98[0][0]             \n",
            "                                                                 conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 8, 8, 168)    672         concatenate_99[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 8, 8, 168)    0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 8, 8, 6)      9072        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_100 (Concatenate)   (None, 8, 8, 174)    0           concatenate_99[0][0]             \n",
            "                                                                 conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 8, 8, 174)    696         concatenate_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 8, 8, 174)    0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 8, 8, 6)      9396        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_101 (Concatenate)   (None, 8, 8, 180)    0           concatenate_100[0][0]            \n",
            "                                                                 conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 8, 8, 180)    720         concatenate_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 8, 8, 180)    0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 8, 8, 6)      9720        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_102 (Concatenate)   (None, 8, 8, 186)    0           concatenate_101[0][0]            \n",
            "                                                                 conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 8, 8, 186)    744         concatenate_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 8, 8, 186)    0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 8, 8, 6)      10044       activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_103 (Concatenate)   (None, 8, 8, 192)    0           concatenate_102[0][0]            \n",
            "                                                                 conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 8, 8, 192)    768         concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 8, 8, 192)    0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 8, 8, 6)      10368       activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_104 (Concatenate)   (None, 8, 8, 198)    0           concatenate_103[0][0]            \n",
            "                                                                 conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 8, 8, 198)    792         concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 8, 8, 198)    0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 8, 8, 6)      10692       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_105 (Concatenate)   (None, 8, 8, 204)    0           concatenate_104[0][0]            \n",
            "                                                                 conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 8, 8, 204)    816         concatenate_105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 8, 8, 204)    0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 8, 8, 6)      11016       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_106 (Concatenate)   (None, 8, 8, 210)    0           concatenate_105[0][0]            \n",
            "                                                                 conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 8, 8, 210)    840         concatenate_106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 8, 8, 210)    0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 8, 8, 6)      11340       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_107 (Concatenate)   (None, 8, 8, 216)    0           concatenate_106[0][0]            \n",
            "                                                                 conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 8, 8, 216)    864         concatenate_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 8, 8, 216)    0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 8, 8, 6)      11664       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_108 (Concatenate)   (None, 8, 8, 222)    0           concatenate_107[0][0]            \n",
            "                                                                 conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 8, 8, 222)    888         concatenate_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 8, 8, 222)    0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 8, 8, 6)      1332        activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 4, 4, 6)      0           conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 4, 4, 6)      24          average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 4, 4, 6)      0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 4, 4, 6)      324         activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_109 (Concatenate)   (None, 4, 4, 12)     0           average_pooling2d_3[0][0]        \n",
            "                                                                 conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 4, 4, 12)     48          concatenate_109[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 4, 4, 12)     0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 4, 4, 6)      648         activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_110 (Concatenate)   (None, 4, 4, 18)     0           concatenate_109[0][0]            \n",
            "                                                                 conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 4, 4, 18)     72          concatenate_110[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 4, 4, 18)     0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 4, 4, 6)      972         activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_111 (Concatenate)   (None, 4, 4, 24)     0           concatenate_110[0][0]            \n",
            "                                                                 conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 4, 4, 24)     96          concatenate_111[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 4, 4, 24)     0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 4, 4, 6)      1296        activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_112 (Concatenate)   (None, 4, 4, 30)     0           concatenate_111[0][0]            \n",
            "                                                                 conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 4, 4, 30)     120         concatenate_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 4, 4, 30)     0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 4, 4, 6)      1620        activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_113 (Concatenate)   (None, 4, 4, 36)     0           concatenate_112[0][0]            \n",
            "                                                                 conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 4, 4, 36)     144         concatenate_113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 4, 4, 36)     0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 4, 4, 6)      1944        activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_114 (Concatenate)   (None, 4, 4, 42)     0           concatenate_113[0][0]            \n",
            "                                                                 conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 4, 4, 42)     168         concatenate_114[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 4, 4, 42)     0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 4, 4, 6)      2268        activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_115 (Concatenate)   (None, 4, 4, 48)     0           concatenate_114[0][0]            \n",
            "                                                                 conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 4, 4, 48)     192         concatenate_115[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 4, 4, 48)     0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 4, 4, 6)      2592        activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_116 (Concatenate)   (None, 4, 4, 54)     0           concatenate_115[0][0]            \n",
            "                                                                 conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 4, 4, 54)     216         concatenate_116[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 4, 4, 54)     0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 4, 4, 6)      2916        activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_117 (Concatenate)   (None, 4, 4, 60)     0           concatenate_116[0][0]            \n",
            "                                                                 conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 4, 4, 60)     240         concatenate_117[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 4, 4, 60)     0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 4, 4, 6)      3240        activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_118 (Concatenate)   (None, 4, 4, 66)     0           concatenate_117[0][0]            \n",
            "                                                                 conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 4, 4, 66)     264         concatenate_118[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 4, 4, 66)     0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 4, 4, 6)      3564        activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_119 (Concatenate)   (None, 4, 4, 72)     0           concatenate_118[0][0]            \n",
            "                                                                 conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 4, 4, 72)     288         concatenate_119[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 4, 4, 72)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 4, 4, 6)      3888        activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_120 (Concatenate)   (None, 4, 4, 78)     0           concatenate_119[0][0]            \n",
            "                                                                 conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 4, 4, 78)     312         concatenate_120[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 4, 4, 78)     0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 4, 4, 6)      4212        activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_121 (Concatenate)   (None, 4, 4, 84)     0           concatenate_120[0][0]            \n",
            "                                                                 conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 4, 4, 84)     336         concatenate_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 4, 4, 84)     0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 4, 4, 6)      4536        activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_122 (Concatenate)   (None, 4, 4, 90)     0           concatenate_121[0][0]            \n",
            "                                                                 conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 4, 4, 90)     360         concatenate_122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 4, 4, 90)     0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 4, 4, 6)      4860        activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_123 (Concatenate)   (None, 4, 4, 96)     0           concatenate_122[0][0]            \n",
            "                                                                 conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 4, 4, 96)     384         concatenate_123[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 4, 4, 96)     0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 4, 4, 6)      5184        activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_124 (Concatenate)   (None, 4, 4, 102)    0           concatenate_123[0][0]            \n",
            "                                                                 conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 4, 4, 102)    408         concatenate_124[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 4, 4, 102)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 4, 4, 6)      5508        activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_125 (Concatenate)   (None, 4, 4, 108)    0           concatenate_124[0][0]            \n",
            "                                                                 conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 4, 4, 108)    432         concatenate_125[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 4, 4, 108)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 4, 4, 6)      5832        activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_126 (Concatenate)   (None, 4, 4, 114)    0           concatenate_125[0][0]            \n",
            "                                                                 conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 4, 4, 114)    456         concatenate_126[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 4, 4, 114)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 4, 4, 6)      6156        activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_127 (Concatenate)   (None, 4, 4, 120)    0           concatenate_126[0][0]            \n",
            "                                                                 conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 4, 4, 120)    480         concatenate_127[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 4, 4, 120)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 4, 4, 6)      6480        activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_128 (Concatenate)   (None, 4, 4, 126)    0           concatenate_127[0][0]            \n",
            "                                                                 conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 4, 4, 126)    504         concatenate_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 4, 4, 126)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 4, 4, 6)      6804        activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_129 (Concatenate)   (None, 4, 4, 132)    0           concatenate_128[0][0]            \n",
            "                                                                 conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 4, 4, 132)    528         concatenate_129[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 4, 4, 132)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 4, 4, 6)      7128        activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_130 (Concatenate)   (None, 4, 4, 138)    0           concatenate_129[0][0]            \n",
            "                                                                 conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 4, 4, 138)    552         concatenate_130[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 4, 4, 138)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 4, 4, 6)      7452        activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_131 (Concatenate)   (None, 4, 4, 144)    0           concatenate_130[0][0]            \n",
            "                                                                 conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 4, 4, 144)    576         concatenate_131[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 4, 4, 144)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 4, 4, 6)      7776        activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_132 (Concatenate)   (None, 4, 4, 150)    0           concatenate_131[0][0]            \n",
            "                                                                 conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 4, 4, 150)    600         concatenate_132[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 4, 4, 150)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 4, 4, 6)      8100        activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_133 (Concatenate)   (None, 4, 4, 156)    0           concatenate_132[0][0]            \n",
            "                                                                 conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 4, 4, 156)    624         concatenate_133[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 4, 4, 156)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 4, 4, 6)      8424        activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_134 (Concatenate)   (None, 4, 4, 162)    0           concatenate_133[0][0]            \n",
            "                                                                 conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 4, 4, 162)    648         concatenate_134[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 4, 4, 162)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 4, 4, 6)      8748        activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_135 (Concatenate)   (None, 4, 4, 168)    0           concatenate_134[0][0]            \n",
            "                                                                 conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 4, 4, 168)    672         concatenate_135[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 4, 4, 168)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 4, 4, 6)      9072        activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_136 (Concatenate)   (None, 4, 4, 174)    0           concatenate_135[0][0]            \n",
            "                                                                 conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 4, 4, 174)    696         concatenate_136[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 4, 4, 174)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 4, 4, 6)      9396        activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_137 (Concatenate)   (None, 4, 4, 180)    0           concatenate_136[0][0]            \n",
            "                                                                 conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 4, 4, 180)    720         concatenate_137[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 4, 4, 180)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 4, 4, 6)      9720        activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_138 (Concatenate)   (None, 4, 4, 186)    0           concatenate_137[0][0]            \n",
            "                                                                 conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 4, 4, 186)    744         concatenate_138[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 4, 4, 186)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 4, 4, 6)      10044       activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_139 (Concatenate)   (None, 4, 4, 192)    0           concatenate_138[0][0]            \n",
            "                                                                 conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 4, 4, 192)    768         concatenate_139[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 4, 4, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 4, 4, 6)      10368       activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_140 (Concatenate)   (None, 4, 4, 198)    0           concatenate_139[0][0]            \n",
            "                                                                 conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 4, 4, 198)    792         concatenate_140[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 4, 4, 198)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 4, 4, 6)      10692       activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_141 (Concatenate)   (None, 4, 4, 204)    0           concatenate_140[0][0]            \n",
            "                                                                 conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 4, 4, 204)    816         concatenate_141[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 4, 4, 204)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 4, 4, 6)      11016       activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_142 (Concatenate)   (None, 4, 4, 210)    0           concatenate_141[0][0]            \n",
            "                                                                 conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 4, 4, 210)    840         concatenate_142[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 4, 4, 210)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 4, 4, 6)      11340       activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_143 (Concatenate)   (None, 4, 4, 216)    0           concatenate_142[0][0]            \n",
            "                                                                 conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 4, 4, 216)    864         concatenate_143[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 4, 4, 216)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 4, 4, 6)      11664       activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_144 (Concatenate)   (None, 4, 4, 222)    0           concatenate_143[0][0]            \n",
            "                                                                 conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 4, 4, 222)    888         concatenate_144[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 4, 4, 222)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 4, 4, 10)     2220        activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 2, 2, 10)     0           conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 10)           0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 10)           0           global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 958,252\n",
            "Trainable params: 923,768\n",
            "Non-trainable params: 34,484\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-4l2tnQmHxV3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "def step_lr(epoch):\n",
        "    initial_lr = 0.1\n",
        "    if epoch>=90:\n",
        "        learning_rate = initial_lr/10\n",
        "    if epoch>=135:\n",
        "        learning_rate = initial_lr/100\n",
        "    if epoch<90:\n",
        "        learning_rate = initial_lr\n",
        "    return learning_rate\n",
        "\n",
        "lrate = LearningRateScheduler(step_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.1, decay=1e-4, momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xf7ATMSbIBEJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    #zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    # randomly shift images horizontally (fraction of total width)\n",
        "    width_shift_range=0.2,\n",
        "    # randomly shift images vertically (fraction of total height)\n",
        "    height_shift_range=0.2,\n",
        "    #shear_range=0.2,  # set range for random shear(init-0)\n",
        "    #zoom_range=0.2,  # set range for random zoom(init-0)\n",
        "    channel_shift_range=0.,  # set range for random channel shifts\n",
        "    # set mode for filling points outside the input boundaries\n",
        "    fill_mode='nearest',\n",
        "    cval=0.,  # value used for fill_mode = \"constant\"\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False,  # randomly flip images\n",
        "    # set rescaling factor (applied before any other transformation)\n",
        "    rescale=None,\n",
        "    # set function that will be applied on each input\n",
        "    preprocessing_function=None,\n",
        "    # image data format, either \"channels_first\" or \"channels_last\"\n",
        "    data_format=None,\n",
        "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "    validation_split=0.0)\n",
        "\n",
        "# Compute quantities required for feature-wise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TKDMt8eRIEHo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Logger(keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        print('current_learning_rate:',k.eval(self.model.optimizer.lr))\n",
        "  \n",
        "\n",
        "lr_log = Logger()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4VT3PQb8e8wM",
        "colab_type": "code",
        "outputId": "038c5ee6-6808-4dc9-ddb5-a5ad0173d3f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HzatmAe2IPqP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "checkpoint_path = \"/content/gdrive/My Drive/densenet_training/cp1-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, verbose=1, save_weights_only=True, period=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lowB11lrZqsJ",
        "colab_type": "code",
        "outputId": "324faacf-58e0-4db5-b994-e63f7be9eb5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls gdrive\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'My Drive'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "outputId": "6abd0528-465d-48ed-ff31-a30118a8ed64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2842
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                 batch_size=batch_size),\n",
        "                    epochs=epochs,steps_per_epoch=x_train.shape[0]//batch_size,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    validation_steps = x_test.shape[0]//batch_size,\n",
        "                    #use_multiprocessing=True,\n",
        "                    callbacks=[ lrate, lr_log, cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/250\n",
            "781/781 [==============================] - 686s 878ms/step - loss: 1.8104 - acc: 0.3296 - val_loss: 1.6286 - val_acc: 0.4038\n",
            "current_learning_rate: 0.1\n",
            "Epoch 2/250\n",
            "781/781 [==============================] - 643s 823ms/step - loss: 1.5078 - acc: 0.4435 - val_loss: 2.2161 - val_acc: 0.3551\n",
            "current_learning_rate: 0.1\n",
            "Epoch 3/250\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 1.3413 - acc: 0.5116 - val_loss: 1.3574 - val_acc: 0.5300\n",
            "current_learning_rate: 0.1\n",
            "Epoch 4/250\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 1.2095 - acc: 0.5592 - val_loss: 1.2202 - val_acc: 0.5696\n",
            "current_learning_rate: 0.1\n",
            "Epoch 5/250\n",
            "781/781 [==============================] - 640s 820ms/step - loss: 1.0936 - acc: 0.6071 - val_loss: 1.7269 - val_acc: 0.4986\n",
            "current_learning_rate: 0.1\n",
            "Epoch 6/250\n",
            "781/781 [==============================] - 639s 818ms/step - loss: 1.0128 - acc: 0.6391 - val_loss: 0.9576 - val_acc: 0.6686\n",
            "current_learning_rate: 0.1\n",
            "Epoch 7/250\n",
            "781/781 [==============================] - 639s 818ms/step - loss: 0.9607 - acc: 0.6579 - val_loss: 1.3320 - val_acc: 0.5910\n",
            "current_learning_rate: 0.1\n",
            "Epoch 8/250\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 0.9025 - acc: 0.6798 - val_loss: 1.3582 - val_acc: 0.5984\n",
            "current_learning_rate: 0.1\n",
            "Epoch 9/250\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 0.8616 - acc: 0.6947 - val_loss: 1.4658 - val_acc: 0.5835\n",
            "current_learning_rate: 0.1\n",
            "Epoch 10/250\n",
            "781/781 [==============================] - 639s 819ms/step - loss: 0.8179 - acc: 0.7116 - val_loss: 0.8510 - val_acc: 0.7112\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/densenet_training/cp1-0010.ckpt\n",
            "Epoch 11/250\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.7802 - acc: 0.7268 - val_loss: 0.9374 - val_acc: 0.6899\n",
            "current_learning_rate: 0.1\n",
            "Epoch 12/250\n",
            "781/781 [==============================] - 640s 820ms/step - loss: 0.7541 - acc: 0.7355 - val_loss: 0.7471 - val_acc: 0.7502\n",
            "current_learning_rate: 0.1\n",
            "Epoch 13/250\n",
            "781/781 [==============================] - 641s 820ms/step - loss: 0.7259 - acc: 0.7460 - val_loss: 0.7891 - val_acc: 0.7316\n",
            "current_learning_rate: 0.1\n",
            "Epoch 14/250\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.7061 - acc: 0.7535 - val_loss: 0.7437 - val_acc: 0.7431\n",
            "current_learning_rate: 0.1\n",
            "Epoch 15/250\n",
            "781/781 [==============================] - 640s 819ms/step - loss: 0.6839 - acc: 0.7619 - val_loss: 0.7823 - val_acc: 0.7409\n",
            "current_learning_rate: 0.1\n",
            "Epoch 16/250\n",
            "781/781 [==============================] - 640s 819ms/step - loss: 0.6563 - acc: 0.7741 - val_loss: 0.7731 - val_acc: 0.7446\n",
            "current_learning_rate: 0.1\n",
            "Epoch 17/250\n",
            "781/781 [==============================] - 639s 819ms/step - loss: 0.6433 - acc: 0.7751 - val_loss: 0.6168 - val_acc: 0.7902\n",
            "current_learning_rate: 0.1\n",
            "Epoch 18/250\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 0.6210 - acc: 0.7843 - val_loss: 0.6348 - val_acc: 0.7825\n",
            "current_learning_rate: 0.1\n",
            "Epoch 19/250\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 0.6144 - acc: 0.7857 - val_loss: 0.6519 - val_acc: 0.7838\n",
            "current_learning_rate: 0.1\n",
            "Epoch 20/250\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.5951 - acc: 0.7919 - val_loss: 0.6676 - val_acc: 0.7784\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00020: saving model to /content/gdrive/My Drive/densenet_training/cp1-0020.ckpt\n",
            "Epoch 21/250\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.5813 - acc: 0.7964 - val_loss: 0.6122 - val_acc: 0.7897\n",
            "current_learning_rate: 0.1\n",
            "Epoch 22/250\n",
            "781/781 [==============================] - 641s 820ms/step - loss: 0.5690 - acc: 0.8044 - val_loss: 0.6076 - val_acc: 0.7973\n",
            "current_learning_rate: 0.1\n",
            "Epoch 23/250\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 0.5621 - acc: 0.8055 - val_loss: 0.6279 - val_acc: 0.7907\n",
            "current_learning_rate: 0.1\n",
            "Epoch 24/250\n",
            "781/781 [==============================] - 643s 823ms/step - loss: 0.5466 - acc: 0.8114 - val_loss: 0.6493 - val_acc: 0.7905\n",
            "current_learning_rate: 0.1\n",
            "Epoch 25/250\n",
            "781/781 [==============================] - 644s 824ms/step - loss: 0.5317 - acc: 0.8154 - val_loss: 0.6057 - val_acc: 0.7982\n",
            "current_learning_rate: 0.1\n",
            "Epoch 26/250\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 0.5241 - acc: 0.8185 - val_loss: 0.5211 - val_acc: 0.8259\n",
            "current_learning_rate: 0.1\n",
            "Epoch 27/250\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.5152 - acc: 0.8203 - val_loss: 0.5092 - val_acc: 0.8305\n",
            "current_learning_rate: 0.1\n",
            "Epoch 28/250\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.4985 - acc: 0.8272 - val_loss: 0.6161 - val_acc: 0.7933\n",
            "current_learning_rate: 0.1\n",
            "Epoch 29/250\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.4939 - acc: 0.8296 - val_loss: 0.6708 - val_acc: 0.7813\n",
            "current_learning_rate: 0.1\n",
            "Epoch 30/250\n",
            "781/781 [==============================] - 645s 825ms/step - loss: 0.4897 - acc: 0.8285 - val_loss: 0.6948 - val_acc: 0.7818\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00030: saving model to /content/gdrive/My Drive/densenet_training/cp1-0030.ckpt\n",
            "Epoch 31/250\n",
            "781/781 [==============================] - 641s 820ms/step - loss: 0.4762 - acc: 0.8350 - val_loss: 0.6727 - val_acc: 0.7853\n",
            "current_learning_rate: 0.1\n",
            "Epoch 32/250\n",
            "781/781 [==============================] - 641s 820ms/step - loss: 0.4738 - acc: 0.8356 - val_loss: 0.6281 - val_acc: 0.8008\n",
            "current_learning_rate: 0.1\n",
            "Epoch 33/250\n",
            "781/781 [==============================] - 641s 820ms/step - loss: 0.4610 - acc: 0.8398 - val_loss: 0.5357 - val_acc: 0.8212\n",
            "current_learning_rate: 0.1\n",
            "Epoch 34/250\n",
            "781/781 [==============================] - 640s 819ms/step - loss: 0.4556 - acc: 0.8405 - val_loss: 0.6612 - val_acc: 0.7984\n",
            "current_learning_rate: 0.1\n",
            "Epoch 35/250\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.4495 - acc: 0.8433 - val_loss: 0.5770 - val_acc: 0.8116\n",
            "current_learning_rate: 0.1\n",
            "Epoch 36/250\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.4463 - acc: 0.8460 - val_loss: 0.5383 - val_acc: 0.8252\n",
            "current_learning_rate: 0.1\n",
            "Epoch 37/250\n",
            "781/781 [==============================] - 640s 820ms/step - loss: 0.4371 - acc: 0.8494 - val_loss: 0.4980 - val_acc: 0.8391\n",
            "current_learning_rate: 0.1\n",
            "Epoch 38/250\n",
            "781/781 [==============================] - 643s 823ms/step - loss: 0.4290 - acc: 0.8507 - val_loss: 0.5072 - val_acc: 0.8317\n",
            "current_learning_rate: 0.1\n",
            "Epoch 39/250\n",
            "781/781 [==============================] - 641s 820ms/step - loss: 0.4276 - acc: 0.8514 - val_loss: 0.6541 - val_acc: 0.7989\n",
            "current_learning_rate: 0.1\n",
            "Epoch 40/250\n",
            "781/781 [==============================] - 641s 820ms/step - loss: 0.4250 - acc: 0.8520 - val_loss: 0.5714 - val_acc: 0.8205\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00040: saving model to /content/gdrive/My Drive/densenet_training/cp1-0040.ckpt\n",
            "Epoch 41/250\n",
            "781/781 [==============================] - 640s 820ms/step - loss: 0.4162 - acc: 0.8539 - val_loss: 0.5242 - val_acc: 0.8334\n",
            "current_learning_rate: 0.1\n",
            "Epoch 42/250\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 0.4116 - acc: 0.8554 - val_loss: 0.4563 - val_acc: 0.8490\n",
            "current_learning_rate: 0.1\n",
            "Epoch 43/250\n",
            "781/781 [==============================] - 647s 829ms/step - loss: 0.4044 - acc: 0.8587 - val_loss: 0.5320 - val_acc: 0.8276\n",
            "current_learning_rate: 0.1\n",
            "Epoch 44/250\n",
            "781/781 [==============================] - 646s 828ms/step - loss: 0.3961 - acc: 0.8626 - val_loss: 0.5179 - val_acc: 0.8323\n",
            "current_learning_rate: 0.1\n",
            "Epoch 45/250\n",
            "781/781 [==============================] - 647s 828ms/step - loss: 0.3940 - acc: 0.8633 - val_loss: 0.5368 - val_acc: 0.8307\n",
            "current_learning_rate: 0.1\n",
            "Epoch 46/250\n",
            "781/781 [==============================] - 646s 827ms/step - loss: 0.3883 - acc: 0.8638 - val_loss: 0.4810 - val_acc: 0.8458\n",
            "current_learning_rate: 0.1\n",
            "Epoch 47/250\n",
            "781/781 [==============================] - 646s 827ms/step - loss: 0.3853 - acc: 0.8661 - val_loss: 0.5912 - val_acc: 0.8173\n",
            "current_learning_rate: 0.1\n",
            "Epoch 48/250\n",
            "781/781 [==============================] - 645s 826ms/step - loss: 0.3837 - acc: 0.8678 - val_loss: 0.4328 - val_acc: 0.8551\n",
            "current_learning_rate: 0.1\n",
            "Epoch 49/250\n",
            "781/781 [==============================] - 645s 825ms/step - loss: 0.3731 - acc: 0.8710 - val_loss: 0.5293 - val_acc: 0.8334\n",
            "current_learning_rate: 0.1\n",
            "Epoch 50/250\n",
            "781/781 [==============================] - 644s 824ms/step - loss: 0.3774 - acc: 0.8685 - val_loss: 0.4255 - val_acc: 0.8561\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00050: saving model to /content/gdrive/My Drive/densenet_training/cp1-0050.ckpt\n",
            "Epoch 51/250\n",
            "284/781 [=========>....................] - ETA: 6:27 - loss: 0.3644 - acc: 0.8721"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_znmNehAJgO8",
        "colab_type": "code",
        "outputId": "ce177298-ff0d-4f3f-ec96-a74dc3c442db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "! ls {checkpoint_dir}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xVUz6x8fH8MH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/gdrive/My Drive/densenet_training/cp1-0050.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Vne9rHOSHSV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training after 50th epoch\n",
        "epochs=200\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def step_lr(epoch):\n",
        "    initial_lr = 0.1\n",
        "    if epoch>=40:\n",
        "        learning_rate = initial_lr/10\n",
        "    if epoch>=85:\n",
        "        learning_rate = initial_lr/100\n",
        "    if epoch<40:\n",
        "        learning_rate = initial_lr\n",
        "    return learning_rate\n",
        "\n",
        "lrate = LearningRateScheduler(step_lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "op1RPmPeSnp4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#checkpoints after 50th epoch\n",
        "import os\n",
        "checkpoint_path = \"/content/gdrive/My Drive/densenet_training/cp1-50-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, verbose=1, save_weights_only=True, period=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gqe5dN8aS8YC",
        "colab_type": "code",
        "outputId": "7c89bec7-af43-469a-fc95-92c4d3548696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2159
        }
      },
      "cell_type": "code",
      "source": [
        "#Resume training \n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                 batch_size=batch_size),\n",
        "                    epochs=epochs,steps_per_epoch=x_train.shape[0]//batch_size,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    validation_steps = x_test.shape[0]//batch_size,\n",
        "                    \n",
        "                    #use_multiprocessing=True,\n",
        "                    callbacks=[ lrate, lr_log, cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "781/781 [==============================] - 660s 845ms/step - loss: 0.4625 - acc: 0.8372 - val_loss: 0.7676 - val_acc: 0.7670\n",
            "current_learning_rate: 0.1\n",
            "Epoch 2/200\n",
            "781/781 [==============================] - 661s 846ms/step - loss: 0.4563 - acc: 0.8416 - val_loss: 0.4950 - val_acc: 0.8343\n",
            "current_learning_rate: 0.1\n",
            "Epoch 3/200\n",
            "781/781 [==============================] - 661s 847ms/step - loss: 0.4385 - acc: 0.8476 - val_loss: 0.5117 - val_acc: 0.8283\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/densenet_training/cp1-50-0003.ckpt\n",
            "Epoch 4/200\n",
            "781/781 [==============================] - 661s 846ms/step - loss: 0.4295 - acc: 0.8497 - val_loss: 0.5208 - val_acc: 0.8281\n",
            "current_learning_rate: 0.1\n",
            "Epoch 5/200\n",
            "781/781 [==============================] - 661s 846ms/step - loss: 0.4231 - acc: 0.8529 - val_loss: 0.5685 - val_acc: 0.8174\n",
            "current_learning_rate: 0.1\n",
            "Epoch 6/200\n",
            "781/781 [==============================] - 661s 847ms/step - loss: 0.4126 - acc: 0.8555 - val_loss: 0.5226 - val_acc: 0.8326\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/densenet_training/cp1-50-0006.ckpt\n",
            "Epoch 7/200\n",
            "781/781 [==============================] - 662s 848ms/step - loss: 0.4004 - acc: 0.8599 - val_loss: 0.5020 - val_acc: 0.8352\n",
            "current_learning_rate: 0.1\n",
            "Epoch 8/200\n",
            "781/781 [==============================] - 662s 847ms/step - loss: 0.3914 - acc: 0.8653 - val_loss: 0.5606 - val_acc: 0.8289\n",
            "current_learning_rate: 0.1\n",
            "Epoch 9/200\n",
            "781/781 [==============================] - 662s 848ms/step - loss: 0.3879 - acc: 0.8643 - val_loss: 0.5620 - val_acc: 0.8201\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/densenet_training/cp1-50-0009.ckpt\n",
            "Epoch 10/200\n",
            "781/781 [==============================] - 662s 847ms/step - loss: 0.3814 - acc: 0.8658 - val_loss: 0.6039 - val_acc: 0.8149\n",
            "current_learning_rate: 0.1\n",
            "Epoch 11/200\n",
            "781/781 [==============================] - 662s 848ms/step - loss: 0.3700 - acc: 0.8707 - val_loss: 0.6989 - val_acc: 0.7939\n",
            "current_learning_rate: 0.1\n",
            "Epoch 12/200\n",
            "781/781 [==============================] - 662s 848ms/step - loss: 0.3669 - acc: 0.8723 - val_loss: 0.4368 - val_acc: 0.8549\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00012: saving model to /content/gdrive/My Drive/densenet_training/cp1-50-0012.ckpt\n",
            "Epoch 13/200\n",
            "781/781 [==============================] - 664s 850ms/step - loss: 0.3612 - acc: 0.8753 - val_loss: 0.5628 - val_acc: 0.8240\n",
            "current_learning_rate: 0.1\n",
            "Epoch 14/200\n",
            "781/781 [==============================] - 663s 849ms/step - loss: 0.3547 - acc: 0.8770 - val_loss: 0.5233 - val_acc: 0.8388\n",
            "current_learning_rate: 0.1\n",
            "Epoch 15/200\n",
            "781/781 [==============================] - 663s 849ms/step - loss: 0.3473 - acc: 0.8794 - val_loss: 0.5256 - val_acc: 0.8342\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00015: saving model to /content/gdrive/My Drive/densenet_training/cp1-50-0015.ckpt\n",
            "Epoch 16/200\n",
            "781/781 [==============================] - 662s 848ms/step - loss: 0.3483 - acc: 0.8799 - val_loss: 0.4890 - val_acc: 0.8393\n",
            "current_learning_rate: 0.1\n",
            "Epoch 17/200\n",
            "781/781 [==============================] - 653s 836ms/step - loss: 0.3378 - acc: 0.8811 - val_loss: 0.4802 - val_acc: 0.8512\n",
            "current_learning_rate: 0.1\n",
            "Epoch 18/200\n",
            "781/781 [==============================] - 654s 837ms/step - loss: 0.3360 - acc: 0.8835 - val_loss: 0.4225 - val_acc: 0.8608\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00018: saving model to /content/gdrive/My Drive/densenet_training/cp1-50-0018.ckpt\n",
            "Epoch 19/200\n",
            "781/781 [==============================] - 654s 837ms/step - loss: 0.3285 - acc: 0.8861 - val_loss: 0.4435 - val_acc: 0.8545\n",
            "current_learning_rate: 0.1\n",
            "Epoch 20/200\n",
            "781/781 [==============================] - 652s 835ms/step - loss: 0.3268 - acc: 0.8853 - val_loss: 0.4523 - val_acc: 0.8590\n",
            "current_learning_rate: 0.1\n",
            "Epoch 21/200\n",
            "781/781 [==============================] - 653s 835ms/step - loss: 0.3184 - acc: 0.8901 - val_loss: 0.5156 - val_acc: 0.8375\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00021: saving model to /content/gdrive/My Drive/densenet_training/cp1-50-0021.ckpt\n",
            "Epoch 22/200\n",
            "781/781 [==============================] - 653s 836ms/step - loss: 0.3144 - acc: 0.8920 - val_loss: 0.3959 - val_acc: 0.8704\n",
            "current_learning_rate: 0.1\n",
            "Epoch 23/200\n",
            "781/781 [==============================] - 662s 847ms/step - loss: 0.3171 - acc: 0.8878 - val_loss: 0.4171 - val_acc: 0.8648\n",
            "current_learning_rate: 0.1\n",
            "Epoch 24/200\n",
            "781/781 [==============================] - 663s 849ms/step - loss: 0.3098 - acc: 0.8917 - val_loss: 0.4741 - val_acc: 0.8520\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00024: saving model to /content/gdrive/My Drive/densenet_training/cp1-50-0024.ckpt\n",
            "Epoch 25/200\n",
            "781/781 [==============================] - 664s 850ms/step - loss: 0.3041 - acc: 0.8937 - val_loss: 0.5023 - val_acc: 0.8482\n",
            "current_learning_rate: 0.1\n",
            "Epoch 26/200\n",
            "781/781 [==============================] - 664s 850ms/step - loss: 0.2981 - acc: 0.8965 - val_loss: 0.4564 - val_acc: 0.8588\n",
            "current_learning_rate: 0.1\n",
            "Epoch 27/200\n",
            "781/781 [==============================] - 663s 849ms/step - loss: 0.2951 - acc: 0.8972 - val_loss: 0.4216 - val_acc: 0.8644\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00027: saving model to /content/gdrive/My Drive/densenet_training/cp1-50-0027.ckpt\n",
            "Epoch 28/200\n",
            "781/781 [==============================] - 663s 849ms/step - loss: 0.2983 - acc: 0.8960 - val_loss: 0.4691 - val_acc: 0.8504\n",
            "current_learning_rate: 0.1\n",
            "Epoch 29/200\n",
            "781/781 [==============================] - 664s 850ms/step - loss: 0.2921 - acc: 0.8990 - val_loss: 0.3725 - val_acc: 0.8793\n",
            "current_learning_rate: 0.1\n",
            "Epoch 30/200\n",
            "781/781 [==============================] - 663s 849ms/step - loss: 0.2902 - acc: 0.9000 - val_loss: 0.4238 - val_acc: 0.8662\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00030: saving model to /content/gdrive/My Drive/densenet_training/cp1-50-0030.ckpt\n",
            "Epoch 31/200\n",
            "781/781 [==============================] - 664s 850ms/step - loss: 0.2823 - acc: 0.9018 - val_loss: 0.4102 - val_acc: 0.8646\n",
            "current_learning_rate: 0.1\n",
            "Epoch 32/200\n",
            "781/781 [==============================] - 664s 850ms/step - loss: 0.2794 - acc: 0.9021 - val_loss: 0.5031 - val_acc: 0.8424\n",
            "current_learning_rate: 0.1\n",
            "Epoch 33/200\n",
            "781/781 [==============================] - 664s 851ms/step - loss: 0.2806 - acc: 0.9024 - val_loss: 0.3749 - val_acc: 0.8761\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00033: saving model to /content/gdrive/My Drive/densenet_training/cp1-50-0033.ckpt\n",
            "Epoch 34/200\n",
            "781/781 [==============================] - 664s 850ms/step - loss: 0.2757 - acc: 0.9030 - val_loss: 0.4705 - val_acc: 0.8571\n",
            "current_learning_rate: 0.1\n",
            "Epoch 35/200\n",
            " 30/781 [>.............................] - ETA: 10:05 - loss: 0.2996 - acc: 0.8979"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bncDUh5v7azG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training after 83rd epoch\n",
        "epochs=167\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def step_lr(epoch):\n",
        "    initial_lr = 0.1\n",
        "    if epoch>=7:\n",
        "        learning_rate = initial_lr/10\n",
        "    if epoch>=52:\n",
        "        learning_rate = initial_lr/100\n",
        "    if epoch<7:\n",
        "        learning_rate = initial_lr\n",
        "    return learning_rate\n",
        "\n",
        "lrate = LearningRateScheduler(step_lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yJXX6cKw7bjL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#checkpoints after 83rd epoch\n",
        "import os\n",
        "checkpoint_path = \"/content/gdrive/My Drive/densenet_training/cp1-83-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, verbose=1, save_weights_only=True, period=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aWQkxtZf78Jk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#loading the model\n",
        "model.load_weights('/content/gdrive/My Drive/densenet_training/cp1-50-0033.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_tt8geIo7j9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4151
        },
        "outputId": "ea411adf-9c93-491c-88b3-4e3027b3645f"
      },
      "cell_type": "code",
      "source": [
        "#Resume training \n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                 batch_size=batch_size),\n",
        "                    epochs=epochs,steps_per_epoch=x_train.shape[0]//batch_size,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    validation_steps = x_test.shape[0]//batch_size,\n",
        "                    \n",
        "                    #use_multiprocessing=True,\n",
        "                    callbacks=[ lrate, lr_log, cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/167\n",
            "781/781 [==============================] - 669s 856ms/step - loss: 0.4410 - acc: 0.8470 - val_loss: 0.6139 - val_acc: 0.8016\n",
            "current_learning_rate: 0.1\n",
            "Epoch 2/167\n",
            "781/781 [==============================] - 642s 823ms/step - loss: 0.4193 - acc: 0.8548 - val_loss: 0.7854 - val_acc: 0.7757\n",
            "current_learning_rate: 0.1\n",
            "Epoch 3/167\n",
            "781/781 [==============================] - 642s 821ms/step - loss: 0.3966 - acc: 0.8619 - val_loss: 0.5448 - val_acc: 0.8228\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0003.ckpt\n",
            "Epoch 4/167\n",
            "781/781 [==============================] - 643s 823ms/step - loss: 0.3788 - acc: 0.8677 - val_loss: 0.5342 - val_acc: 0.8291\n",
            "current_learning_rate: 0.1\n",
            "Epoch 5/167\n",
            "781/781 [==============================] - 643s 823ms/step - loss: 0.3718 - acc: 0.8712 - val_loss: 0.5025 - val_acc: 0.8379\n",
            "current_learning_rate: 0.1\n",
            "Epoch 6/167\n",
            "781/781 [==============================] - 643s 823ms/step - loss: 0.3615 - acc: 0.8744 - val_loss: 0.5038 - val_acc: 0.8351\n",
            "current_learning_rate: 0.1\n",
            "\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0006.ckpt\n",
            "Epoch 7/167\n",
            "781/781 [==============================] - 644s 825ms/step - loss: 0.3481 - acc: 0.8782 - val_loss: 0.5167 - val_acc: 0.8374\n",
            "current_learning_rate: 0.1\n",
            "Epoch 8/167\n",
            "781/781 [==============================] - 645s 826ms/step - loss: 0.2859 - acc: 0.9012 - val_loss: 0.3559 - val_acc: 0.8854\n",
            "current_learning_rate: 0.01\n",
            "Epoch 9/167\n",
            "781/781 [==============================] - 645s 826ms/step - loss: 0.2604 - acc: 0.9094 - val_loss: 0.3570 - val_acc: 0.8873\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0009.ckpt\n",
            "Epoch 10/167\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.2534 - acc: 0.9110 - val_loss: 0.3539 - val_acc: 0.8871\n",
            "current_learning_rate: 0.01\n",
            "Epoch 11/167\n",
            "781/781 [==============================] - 645s 825ms/step - loss: 0.2495 - acc: 0.9135 - val_loss: 0.3619 - val_acc: 0.8837\n",
            "current_learning_rate: 0.01\n",
            "Epoch 12/167\n",
            "781/781 [==============================] - 644s 825ms/step - loss: 0.2431 - acc: 0.9164 - val_loss: 0.3596 - val_acc: 0.8841\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00012: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0012.ckpt\n",
            "Epoch 13/167\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.2387 - acc: 0.9162 - val_loss: 0.3523 - val_acc: 0.8869\n",
            "current_learning_rate: 0.01\n",
            "Epoch 14/167\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.2380 - acc: 0.9175 - val_loss: 0.3428 - val_acc: 0.8900\n",
            "current_learning_rate: 0.01\n",
            "Epoch 15/167\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.2360 - acc: 0.9173 - val_loss: 0.3612 - val_acc: 0.8861\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00015: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0015.ckpt\n",
            "Epoch 16/167\n",
            "781/781 [==============================] - 644s 824ms/step - loss: 0.2365 - acc: 0.9179 - val_loss: 0.3516 - val_acc: 0.8872\n",
            "current_learning_rate: 0.01\n",
            "Epoch 17/167\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 0.2305 - acc: 0.9193 - val_loss: 0.3522 - val_acc: 0.8874\n",
            "current_learning_rate: 0.01\n",
            "Epoch 18/167\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.2278 - acc: 0.9213 - val_loss: 0.3458 - val_acc: 0.8894\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00018: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0018.ckpt\n",
            "Epoch 19/167\n",
            "781/781 [==============================] - 641s 821ms/step - loss: 0.2270 - acc: 0.9207 - val_loss: 0.3473 - val_acc: 0.8882\n",
            "current_learning_rate: 0.01\n",
            "Epoch 20/167\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 0.2219 - acc: 0.9223 - val_loss: 0.3407 - val_acc: 0.8906\n",
            "current_learning_rate: 0.01\n",
            "Epoch 21/167\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 0.2258 - acc: 0.9207 - val_loss: 0.3409 - val_acc: 0.8898\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00021: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0021.ckpt\n",
            "Epoch 22/167\n",
            "781/781 [==============================] - 644s 825ms/step - loss: 0.2195 - acc: 0.9228 - val_loss: 0.3496 - val_acc: 0.8897\n",
            "current_learning_rate: 0.01\n",
            "Epoch 23/167\n",
            "781/781 [==============================] - 643s 824ms/step - loss: 0.2208 - acc: 0.9231 - val_loss: 0.3541 - val_acc: 0.8884\n",
            "current_learning_rate: 0.01\n",
            "Epoch 24/167\n",
            "781/781 [==============================] - 644s 825ms/step - loss: 0.2202 - acc: 0.9241 - val_loss: 0.3396 - val_acc: 0.8929\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00024: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0024.ckpt\n",
            "Epoch 25/167\n",
            "781/781 [==============================] - 645s 826ms/step - loss: 0.2212 - acc: 0.9230 - val_loss: 0.3509 - val_acc: 0.8893\n",
            "current_learning_rate: 0.01\n",
            "Epoch 26/167\n",
            "781/781 [==============================] - 647s 829ms/step - loss: 0.2179 - acc: 0.9247 - val_loss: 0.3499 - val_acc: 0.8881\n",
            "current_learning_rate: 0.01\n",
            "Epoch 27/167\n",
            "781/781 [==============================] - 648s 829ms/step - loss: 0.2148 - acc: 0.9245 - val_loss: 0.3552 - val_acc: 0.8879\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00027: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0027.ckpt\n",
            "Epoch 28/167\n",
            "781/781 [==============================] - 648s 829ms/step - loss: 0.2160 - acc: 0.9251 - val_loss: 0.3502 - val_acc: 0.8899\n",
            "current_learning_rate: 0.01\n",
            "Epoch 29/167\n",
            "781/781 [==============================] - 648s 830ms/step - loss: 0.2122 - acc: 0.9258 - val_loss: 0.3426 - val_acc: 0.8916\n",
            "current_learning_rate: 0.01\n",
            "Epoch 30/167\n",
            "781/781 [==============================] - 648s 829ms/step - loss: 0.2123 - acc: 0.9250 - val_loss: 0.3527 - val_acc: 0.8882\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00030: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0030.ckpt\n",
            "Epoch 31/167\n",
            "781/781 [==============================] - 648s 830ms/step - loss: 0.2116 - acc: 0.9262 - val_loss: 0.3489 - val_acc: 0.8904\n",
            "current_learning_rate: 0.01\n",
            "Epoch 32/167\n",
            "781/781 [==============================] - 648s 829ms/step - loss: 0.2103 - acc: 0.9270 - val_loss: 0.3428 - val_acc: 0.8919\n",
            "current_learning_rate: 0.01\n",
            "Epoch 33/167\n",
            "781/781 [==============================] - 648s 829ms/step - loss: 0.2123 - acc: 0.9249 - val_loss: 0.3685 - val_acc: 0.8845\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00033: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0033.ckpt\n",
            "Epoch 34/167\n",
            "781/781 [==============================] - 648s 829ms/step - loss: 0.2110 - acc: 0.9267 - val_loss: 0.3470 - val_acc: 0.8898\n",
            "current_learning_rate: 0.01\n",
            "Epoch 35/167\n",
            "781/781 [==============================] - 648s 829ms/step - loss: 0.2102 - acc: 0.9258 - val_loss: 0.3478 - val_acc: 0.8893\n",
            "current_learning_rate: 0.01\n",
            "Epoch 36/167\n",
            "781/781 [==============================] - 647s 829ms/step - loss: 0.2073 - acc: 0.9265 - val_loss: 0.3505 - val_acc: 0.8881\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00036: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0036.ckpt\n",
            "Epoch 37/167\n",
            "781/781 [==============================] - 647s 829ms/step - loss: 0.2070 - acc: 0.9277 - val_loss: 0.3420 - val_acc: 0.8899\n",
            "current_learning_rate: 0.01\n",
            "Epoch 38/167\n",
            "781/781 [==============================] - 647s 829ms/step - loss: 0.2049 - acc: 0.9281 - val_loss: 0.3572 - val_acc: 0.8860\n",
            "current_learning_rate: 0.01\n",
            "Epoch 39/167\n",
            "781/781 [==============================] - 647s 829ms/step - loss: 0.2041 - acc: 0.9282 - val_loss: 0.3395 - val_acc: 0.8920\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00039: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0039.ckpt\n",
            "Epoch 40/167\n",
            "781/781 [==============================] - 647s 828ms/step - loss: 0.2082 - acc: 0.9276 - val_loss: 0.3461 - val_acc: 0.8906\n",
            "current_learning_rate: 0.01\n",
            "Epoch 41/167\n",
            "781/781 [==============================] - 647s 828ms/step - loss: 0.2078 - acc: 0.9274 - val_loss: 0.3492 - val_acc: 0.8884\n",
            "current_learning_rate: 0.01\n",
            "Epoch 42/167\n",
            "781/781 [==============================] - 648s 829ms/step - loss: 0.2033 - acc: 0.9284 - val_loss: 0.3463 - val_acc: 0.8892\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00042: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0042.ckpt\n",
            "Epoch 43/167\n",
            "781/781 [==============================] - 647s 828ms/step - loss: 0.2082 - acc: 0.9275 - val_loss: 0.3469 - val_acc: 0.8897\n",
            "current_learning_rate: 0.01\n",
            "Epoch 44/167\n",
            "781/781 [==============================] - 644s 825ms/step - loss: 0.2076 - acc: 0.9273 - val_loss: 0.3461 - val_acc: 0.8911\n",
            "current_learning_rate: 0.01\n",
            "Epoch 45/167\n",
            "781/781 [==============================] - 645s 826ms/step - loss: 0.2024 - acc: 0.9286 - val_loss: 0.3330 - val_acc: 0.8936\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00045: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0045.ckpt\n",
            "Epoch 46/167\n",
            "781/781 [==============================] - 647s 828ms/step - loss: 0.2031 - acc: 0.9295 - val_loss: 0.3448 - val_acc: 0.8906\n",
            "current_learning_rate: 0.01\n",
            "Epoch 47/167\n",
            "781/781 [==============================] - 647s 829ms/step - loss: 0.2061 - acc: 0.9279 - val_loss: 0.3523 - val_acc: 0.8890\n",
            "current_learning_rate: 0.01\n",
            "Epoch 48/167\n",
            "781/781 [==============================] - 647s 829ms/step - loss: 0.2020 - acc: 0.9294 - val_loss: 0.3572 - val_acc: 0.8877\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00048: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0048.ckpt\n",
            "Epoch 49/167\n",
            "781/781 [==============================] - 648s 830ms/step - loss: 0.2028 - acc: 0.9285 - val_loss: 0.3369 - val_acc: 0.8918\n",
            "current_learning_rate: 0.01\n",
            "Epoch 50/167\n",
            "781/781 [==============================] - 648s 829ms/step - loss: 0.2011 - acc: 0.9293 - val_loss: 0.3457 - val_acc: 0.8909\n",
            "current_learning_rate: 0.01\n",
            "Epoch 51/167\n",
            "781/781 [==============================] - 644s 825ms/step - loss: 0.2017 - acc: 0.9285 - val_loss: 0.3416 - val_acc: 0.8914\n",
            "current_learning_rate: 0.01\n",
            "\n",
            "Epoch 00051: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0051.ckpt\n",
            "Epoch 52/167\n",
            "781/781 [==============================] - 643s 824ms/step - loss: 0.2000 - acc: 0.9277 - val_loss: 0.3475 - val_acc: 0.8895\n",
            "current_learning_rate: 0.01\n",
            "Epoch 53/167\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 0.2042 - acc: 0.9291 - val_loss: 0.3425 - val_acc: 0.8902\n",
            "current_learning_rate: 0.001\n",
            "Epoch 54/167\n",
            "781/781 [==============================] - 643s 823ms/step - loss: 0.2023 - acc: 0.9292 - val_loss: 0.3413 - val_acc: 0.8922\n",
            "current_learning_rate: 0.001\n",
            "\n",
            "Epoch 00054: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0054.ckpt\n",
            "Epoch 55/167\n",
            "781/781 [==============================] - 643s 823ms/step - loss: 0.1971 - acc: 0.9317 - val_loss: 0.3427 - val_acc: 0.8918\n",
            "current_learning_rate: 0.001\n",
            "Epoch 56/167\n",
            "781/781 [==============================] - 642s 822ms/step - loss: 0.2017 - acc: 0.9293 - val_loss: 0.3424 - val_acc: 0.8914\n",
            "current_learning_rate: 0.001\n",
            "Epoch 57/167\n",
            "781/781 [==============================] - 643s 823ms/step - loss: 0.1973 - acc: 0.9306 - val_loss: 0.3423 - val_acc: 0.8916\n",
            "current_learning_rate: 0.001\n",
            "\n",
            "Epoch 00057: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0057.ckpt\n",
            "Epoch 58/167\n",
            "781/781 [==============================] - 643s 823ms/step - loss: 0.1951 - acc: 0.9329 - val_loss: 0.3430 - val_acc: 0.8920\n",
            "current_learning_rate: 0.001\n",
            "Epoch 59/167\n",
            "781/781 [==============================] - 643s 823ms/step - loss: 0.1946 - acc: 0.9321 - val_loss: 0.3417 - val_acc: 0.8920\n",
            "current_learning_rate: 0.001\n",
            "Epoch 60/167\n",
            "781/781 [==============================] - 643s 823ms/step - loss: 0.1998 - acc: 0.9296 - val_loss: 0.3391 - val_acc: 0.8926\n",
            "current_learning_rate: 0.001\n",
            "\n",
            "Epoch 00060: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0060.ckpt\n",
            "Epoch 61/167\n",
            "781/781 [==============================] - 642s 823ms/step - loss: 0.1999 - acc: 0.9305 - val_loss: 0.3416 - val_acc: 0.8918\n",
            "current_learning_rate: 0.001\n",
            "Epoch 62/167\n",
            "781/781 [==============================] - 644s 825ms/step - loss: 0.1958 - acc: 0.9314 - val_loss: 0.3433 - val_acc: 0.8913\n",
            "current_learning_rate: 0.001\n",
            "Epoch 63/167\n",
            "781/781 [==============================] - 645s 826ms/step - loss: 0.1951 - acc: 0.9305 - val_loss: 0.3437 - val_acc: 0.8919\n",
            "current_learning_rate: 0.001\n",
            "\n",
            "Epoch 00063: saving model to /content/gdrive/My Drive/densenet_training/cp1-83-0063.ckpt\n",
            "Epoch 64/167\n",
            "781/781 [==============================] - 646s 827ms/step - loss: 0.2042 - acc: 0.9283 - val_loss: 0.3447 - val_acc: 0.8908\n",
            "current_learning_rate: 0.001\n",
            "Epoch 65/167\n",
            "781/781 [==============================] - 647s 828ms/step - loss: 0.1983 - acc: 0.9300 - val_loss: 0.3407 - val_acc: 0.8915\n",
            "current_learning_rate: 0.001\n",
            "Epoch 66/167\n",
            "475/781 [=================>............] - ETA: 4:00 - loss: 0.1938 - acc: 0.9315"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PdHHwXxSscml",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "checkpoint_path = \"/content/gdrive/My Drive/densenet_training/cp1-146-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, verbose=1, save_weights_only=True, period=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XPybA8vwsdRH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training after 146th epoch\n",
        "epochs=104\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def step_lr(epoch):\n",
        "    initial_lr = 0.001\n",
        "    if epoch>=20:\n",
        "        learning_rate = initial_lr/10\n",
        "    else:\n",
        "        learning_rate = initial_lr\n",
        "    return learning_rate\n",
        "\n",
        "lrate = LearningRateScheduler(step_lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8LKE0dkMsdtb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#loading the model\n",
        "model.load_weights('/content/gdrive/My Drive/densenet_training/cp1-83-0063.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XiSEA0tMtg6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2529
        },
        "outputId": "b4e3905a-c591-4ee8-a1f3-541fb90dc152"
      },
      "cell_type": "code",
      "source": [
        "#Resume training \n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                 batch_size=batch_size),\n",
        "                    epochs=epochs,steps_per_epoch=x_train.shape[0]//batch_size,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    validation_steps = x_test.shape[0]//batch_size,\n",
        "                    \n",
        "                    #use_multiprocessing=True,\n",
        "                    callbacks=[ lrate, lr_log, cp_callback])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/104\n",
            "781/781 [==============================] - 680s 871ms/step - loss: 0.1953 - acc: 0.9311 - val_loss: 0.3443 - val_acc: 0.8901\n",
            "current_learning_rate: 0.001\n",
            "Epoch 2/104\n",
            "781/781 [==============================] - 656s 840ms/step - loss: 0.1945 - acc: 0.9317 - val_loss: 0.3381 - val_acc: 0.8920\n",
            "current_learning_rate: 0.001\n",
            "Epoch 3/104\n",
            "781/781 [==============================] - 656s 839ms/step - loss: 0.1996 - acc: 0.9301 - val_loss: 0.3438 - val_acc: 0.8910\n",
            "current_learning_rate: 0.001\n",
            "Epoch 4/104\n",
            "781/781 [==============================] - 655s 839ms/step - loss: 0.1964 - acc: 0.9313 - val_loss: 0.3469 - val_acc: 0.8902\n",
            "current_learning_rate: 0.001\n",
            "Epoch 5/104\n",
            "781/781 [==============================] - 654s 837ms/step - loss: 0.1984 - acc: 0.9297 - val_loss: 0.3451 - val_acc: 0.8886\n",
            "current_learning_rate: 0.001\n",
            "Epoch 6/104\n",
            "781/781 [==============================] - 654s 838ms/step - loss: 0.1965 - acc: 0.9309 - val_loss: 0.3417 - val_acc: 0.8903\n",
            "current_learning_rate: 0.001\n",
            "Epoch 7/104\n",
            "781/781 [==============================] - 654s 837ms/step - loss: 0.1967 - acc: 0.9304 - val_loss: 0.3432 - val_acc: 0.8903\n",
            "current_learning_rate: 0.001\n",
            "Epoch 8/104\n",
            "781/781 [==============================] - 654s 838ms/step - loss: 0.1985 - acc: 0.9302 - val_loss: 0.3428 - val_acc: 0.8923\n",
            "current_learning_rate: 0.001\n",
            "Epoch 9/104\n",
            "781/781 [==============================] - 653s 837ms/step - loss: 0.1949 - acc: 0.9321 - val_loss: 0.3410 - val_acc: 0.8907\n",
            "current_learning_rate: 0.001\n",
            "Epoch 10/104\n",
            "781/781 [==============================] - 653s 836ms/step - loss: 0.1979 - acc: 0.9308 - val_loss: 0.3399 - val_acc: 0.8916\n",
            "current_learning_rate: 0.001\n",
            "\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/densenet_training/cp1-146-0010.ckpt\n",
            "Epoch 11/104\n",
            "781/781 [==============================] - 653s 836ms/step - loss: 0.1955 - acc: 0.9315 - val_loss: 0.3416 - val_acc: 0.8915\n",
            "current_learning_rate: 0.001\n",
            "Epoch 12/104\n",
            "781/781 [==============================] - 656s 840ms/step - loss: 0.1983 - acc: 0.9312 - val_loss: 0.3467 - val_acc: 0.8900\n",
            "current_learning_rate: 0.001\n",
            "Epoch 13/104\n",
            "781/781 [==============================] - 653s 836ms/step - loss: 0.1966 - acc: 0.9320 - val_loss: 0.3413 - val_acc: 0.8918\n",
            "current_learning_rate: 0.001\n",
            "Epoch 14/104\n",
            "781/781 [==============================] - 656s 840ms/step - loss: 0.1967 - acc: 0.9301 - val_loss: 0.3395 - val_acc: 0.8929\n",
            "current_learning_rate: 0.001\n",
            "Epoch 15/104\n",
            "781/781 [==============================] - 657s 841ms/step - loss: 0.1918 - acc: 0.9322 - val_loss: 0.3454 - val_acc: 0.8905\n",
            "current_learning_rate: 0.001\n",
            "Epoch 16/104\n",
            "781/781 [==============================] - 658s 843ms/step - loss: 0.1965 - acc: 0.9315 - val_loss: 0.3418 - val_acc: 0.8918\n",
            "current_learning_rate: 0.001\n",
            "Epoch 17/104\n",
            "781/781 [==============================] - 658s 843ms/step - loss: 0.1981 - acc: 0.9306 - val_loss: 0.3390 - val_acc: 0.8933\n",
            "current_learning_rate: 0.001\n",
            "Epoch 18/104\n",
            "781/781 [==============================] - 656s 840ms/step - loss: 0.1977 - acc: 0.9298 - val_loss: 0.3423 - val_acc: 0.8906\n",
            "current_learning_rate: 0.001\n",
            "Epoch 19/104\n",
            "781/781 [==============================] - 657s 842ms/step - loss: 0.1968 - acc: 0.9314 - val_loss: 0.3395 - val_acc: 0.8922\n",
            "current_learning_rate: 0.001\n",
            "Epoch 20/104\n",
            "781/781 [==============================] - 656s 839ms/step - loss: 0.1936 - acc: 0.9320 - val_loss: 0.3423 - val_acc: 0.8919\n",
            "current_learning_rate: 0.001\n",
            "\n",
            "Epoch 00020: saving model to /content/gdrive/My Drive/densenet_training/cp1-146-0020.ckpt\n",
            "Epoch 21/104\n",
            "781/781 [==============================] - 655s 839ms/step - loss: 0.1941 - acc: 0.9312 - val_loss: 0.3433 - val_acc: 0.8922\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 22/104\n",
            "781/781 [==============================] - 655s 838ms/step - loss: 0.1955 - acc: 0.9319 - val_loss: 0.3418 - val_acc: 0.8917\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 23/104\n",
            "781/781 [==============================] - 651s 834ms/step - loss: 0.1950 - acc: 0.9312 - val_loss: 0.3405 - val_acc: 0.8935\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 24/104\n",
            "781/781 [==============================] - 652s 835ms/step - loss: 0.1942 - acc: 0.9306 - val_loss: 0.3405 - val_acc: 0.8930\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 25/104\n",
            "781/781 [==============================] - 653s 836ms/step - loss: 0.1927 - acc: 0.9315 - val_loss: 0.3426 - val_acc: 0.8920\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 26/104\n",
            "781/781 [==============================] - 652s 835ms/step - loss: 0.1926 - acc: 0.9324 - val_loss: 0.3383 - val_acc: 0.8931\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 27/104\n",
            "781/781 [==============================] - 652s 834ms/step - loss: 0.1962 - acc: 0.9309 - val_loss: 0.3399 - val_acc: 0.8928\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 28/104\n",
            "185/781 [======>.......................] - ETA: 7:49 - loss: 0.1928 - acc: 0.9328"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b1c854dae55b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0;31m#use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     callbacks=[ lrate, lr_log, cp_callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "lBcLRrbyzLPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1373
        },
        "outputId": "20c205fe-9db2-4a4a-bca8-72a228cab75a"
      },
      "cell_type": "code",
      "source": [
        "#Resume training \n",
        "batch_size = 128\n",
        "epochs = 104-28\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                 batch_size=batch_size),\n",
        "                    epochs=epochs,steps_per_epoch=x_train.shape[0]//batch_size,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    validation_steps = x_test.shape[0]//batch_size,\n",
        "                    \n",
        "                    #use_multiprocessing=True,\n",
        "                    callbacks=[ lrate, lr_log, cp_callback])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/76\n",
            "390/390 [==============================] - 558s 1s/step - loss: 0.1828 - acc: 0.9358 - val_loss: 0.3418 - val_acc: 0.8931\n",
            "current_learning_rate: 0.001\n",
            "Epoch 2/76\n",
            "390/390 [==============================] - 556s 1s/step - loss: 0.1849 - acc: 0.9360 - val_loss: 0.3408 - val_acc: 0.8923\n",
            "current_learning_rate: 0.001\n",
            "Epoch 3/76\n",
            "390/390 [==============================] - 551s 1s/step - loss: 0.1815 - acc: 0.9365 - val_loss: 0.3429 - val_acc: 0.8913\n",
            "current_learning_rate: 0.001\n",
            "\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/densenet_training/cp1-146-0003.ckpt\n",
            "Epoch 4/76\n",
            "390/390 [==============================] - 551s 1s/step - loss: 0.1821 - acc: 0.9346 - val_loss: 0.3426 - val_acc: 0.8914\n",
            "current_learning_rate: 0.001\n",
            "Epoch 5/76\n",
            "390/390 [==============================] - 552s 1s/step - loss: 0.1839 - acc: 0.9362 - val_loss: 0.3419 - val_acc: 0.8917\n",
            "current_learning_rate: 0.001\n",
            "Epoch 6/76\n",
            " 16/390 [>.............................] - ETA: 8:05 - loss: 0.1811 - acc: 0.9321"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-f107abd19128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0;31m#use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     callbacks=[ lrate, lr_log, cp_callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "E1wnssVezLpG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training after 146th epoch\n",
        "epochs=104-28-6\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def step_lr(epoch):\n",
        "    learning_rate = 0.0001\n",
        "#     if epoch>=20:\n",
        "#         learning_rate = initial_lr/10\n",
        "#     else:\n",
        "#         learning_rate = initial_lr\n",
        "    return learning_rate\n",
        "\n",
        "lrate = LearningRateScheduler(step_lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EJD-sTiJ-YBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1934
        },
        "outputId": "6b203ad7-b04c-4260-c621-701d4a1a9700"
      },
      "cell_type": "code",
      "source": [
        "#Resume training \n",
        "batch_size = 128\n",
        "epochs = 104-28\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                 batch_size=batch_size),\n",
        "                    epochs=epochs,steps_per_epoch=x_train.shape[0]//batch_size,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    validation_steps = x_test.shape[0]//batch_size,\n",
        "                    \n",
        "                    #use_multiprocessing=True,\n",
        "                    callbacks=[ lrate, lr_log, cp_callback])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/76\n",
            "390/390 [==============================] - 552s 1s/step - loss: 0.1842 - acc: 0.9352 - val_loss: 0.3421 - val_acc: 0.8913\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 2/76\n",
            "390/390 [==============================] - 552s 1s/step - loss: 0.1818 - acc: 0.9360 - val_loss: 0.3403 - val_acc: 0.8916\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 3/76\n",
            "390/390 [==============================] - 552s 1s/step - loss: 0.1825 - acc: 0.9364 - val_loss: 0.3430 - val_acc: 0.8909\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 4/76\n",
            "390/390 [==============================] - 552s 1s/step - loss: 0.1819 - acc: 0.9359 - val_loss: 0.3421 - val_acc: 0.8914\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 5/76\n",
            "390/390 [==============================] - 553s 1s/step - loss: 0.1824 - acc: 0.9364 - val_loss: 0.3410 - val_acc: 0.8915\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 6/76\n",
            "390/390 [==============================] - 553s 1s/step - loss: 0.1855 - acc: 0.9346 - val_loss: 0.3424 - val_acc: 0.8911\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 7/76\n",
            "390/390 [==============================] - 553s 1s/step - loss: 0.1830 - acc: 0.9351 - val_loss: 0.3412 - val_acc: 0.8911\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 8/76\n",
            "390/390 [==============================] - 552s 1s/step - loss: 0.1839 - acc: 0.9349 - val_loss: 0.3414 - val_acc: 0.8917\n",
            "current_learning_rate: 1e-04\n",
            "\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/densenet_training/cp1-146-0008.ckpt\n",
            "Epoch 9/76\n",
            "390/390 [==============================] - 552s 1s/step - loss: 0.1824 - acc: 0.9354 - val_loss: 0.3424 - val_acc: 0.8916\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 10/76\n",
            "390/390 [==============================] - 552s 1s/step - loss: 0.1820 - acc: 0.9348 - val_loss: 0.3413 - val_acc: 0.8920\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 11/76\n",
            "390/390 [==============================] - 552s 1s/step - loss: 0.1837 - acc: 0.9353 - val_loss: 0.3429 - val_acc: 0.8914\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 12/76\n",
            "390/390 [==============================] - 550s 1s/step - loss: 0.1818 - acc: 0.9358 - val_loss: 0.3409 - val_acc: 0.8919\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 13/76\n",
            "390/390 [==============================] - 549s 1s/step - loss: 0.1852 - acc: 0.9358 - val_loss: 0.3413 - val_acc: 0.8914\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 14/76\n",
            "390/390 [==============================] - 548s 1s/step - loss: 0.1812 - acc: 0.9361 - val_loss: 0.3419 - val_acc: 0.8910\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 15/76\n",
            "390/390 [==============================] - 549s 1s/step - loss: 0.1800 - acc: 0.9368 - val_loss: 0.3432 - val_acc: 0.8914\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 16/76\n",
            "390/390 [==============================] - 549s 1s/step - loss: 0.1833 - acc: 0.9361 - val_loss: 0.3425 - val_acc: 0.8911\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 17/76\n",
            " 62/390 [===>..........................] - ETA: 7:14 - loss: 0.1912 - acc: 0.9353"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f107abd19128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0;31m#use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     callbacks=[ lrate, lr_log, cp_callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0gfmKcH3gd8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "6a3bb1a1-6977-4c62-fe68-f2162b0c6b34"
      },
      "cell_type": "code",
      "source": [
        "#Resume training \n",
        "batch_size = 32\n",
        "epochs = 104-28\n",
        "model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                 batch_size=batch_size),\n",
        "                    epochs=epochs,steps_per_epoch=x_train.shape[0]//batch_size,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    validation_steps = x_test.shape[0]//batch_size,\n",
        "                    \n",
        "                    #use_multiprocessing=True,\n",
        "                    callbacks=[ lrate, lr_log, cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/76\n",
            "1562/1562 [==============================] - 821s 526ms/step - loss: 0.2185 - acc: 0.9244 - val_loss: 0.3384 - val_acc: 0.8924\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 2/76\n",
            "1562/1562 [==============================] - 823s 527ms/step - loss: 0.2200 - acc: 0.9246 - val_loss: 0.3408 - val_acc: 0.8919\n",
            "current_learning_rate: 1e-04\n",
            "\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/densenet_training/cp1-146-0002.ckpt\n",
            "Epoch 3/76\n",
            "1562/1562 [==============================] - 821s 526ms/step - loss: 0.2181 - acc: 0.9231 - val_loss: 0.3467 - val_acc: 0.8912\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 4/76\n",
            "1562/1562 [==============================] - 825s 528ms/step - loss: 0.2128 - acc: 0.9259 - val_loss: 0.3438 - val_acc: 0.8917\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 5/76\n",
            "1562/1562 [==============================] - 822s 526ms/step - loss: 0.2168 - acc: 0.9249 - val_loss: 0.3440 - val_acc: 0.8921\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 6/76\n",
            "1562/1562 [==============================] - 818s 524ms/step - loss: 0.2166 - acc: 0.9242 - val_loss: 0.3419 - val_acc: 0.8923\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 7/76\n",
            "1562/1562 [==============================] - 816s 523ms/step - loss: 0.2161 - acc: 0.9248 - val_loss: 0.3439 - val_acc: 0.8914\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 8/76\n",
            "1562/1562 [==============================] - 822s 526ms/step - loss: 0.2181 - acc: 0.9253 - val_loss: 0.3414 - val_acc: 0.8929\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 9/76\n",
            "1562/1562 [==============================] - 824s 528ms/step - loss: 0.2170 - acc: 0.9230 - val_loss: 0.3437 - val_acc: 0.8920\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 10/76\n",
            "1562/1562 [==============================] - 825s 528ms/step - loss: 0.2141 - acc: 0.9268 - val_loss: 0.3398 - val_acc: 0.8930\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 11/76\n",
            "1562/1562 [==============================] - 824s 528ms/step - loss: 0.2168 - acc: 0.9230 - val_loss: 0.3389 - val_acc: 0.8925\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 12/76\n",
            "1562/1562 [==============================] - 824s 527ms/step - loss: 0.2163 - acc: 0.9265 - val_loss: 0.3414 - val_acc: 0.8915\n",
            "current_learning_rate: 1e-04\n",
            "\n",
            "Epoch 00012: saving model to /content/gdrive/My Drive/densenet_training/cp1-146-0012.ckpt\n",
            "Epoch 13/76\n",
            "1562/1562 [==============================] - 825s 528ms/step - loss: 0.2142 - acc: 0.9244 - val_loss: 0.3444 - val_acc: 0.8914\n",
            "current_learning_rate: 1e-04\n",
            "Epoch 14/76\n",
            " 330/1562 [=====>........................] - ETA: 10:18 - loss: 0.2129 - acc: 0.9256"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "outputId": "108b2ca9-51f0-42b0-d702-ae1fbf196a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 48s 5ms/step\n",
            "Test loss: 0.3436819578289986\n",
            "Test accuracy: 0.8919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "outputId": "8cc1421a-2b11-413f-ab31-017430a6ab24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model_sota1(77).h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CpWOb6EhTDSW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "outputId": "fc64ae08-20c4-4ff7-b612-6991dc14054f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.save_weights(\"DNST_model_sota1(119).h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3dCjiAaeSt_f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model_sota1(119).h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}